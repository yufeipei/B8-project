{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f072eba",
   "metadata": {},
   "source": [
    "# B8 Software Suite: Analysis of XSPEDS data using Single Photon Counting and Bragg Spectroscopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff4145",
   "metadata": {},
   "source": [
    "### Author: Yufei Pei\n",
    "College: Lady Margaret Hall\n",
    "\n",
    "Supervisor: Prof Sam Vinko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539623cd",
   "metadata": {},
   "source": [
    "## Overview: \n",
    "This software is used to analyse data collected in X-ray Single-Photon Energy-Dispersive Spectroscopy (XSPEDS) experiments. \n",
    "\n",
    "In these experiments, hot, dense plasma sources are created, and the photons emitted from them collected using CCD cameras to study the behaviour of such systems. We are in particular interested in extracting the spectrum of emission intensity vs. photon energy, which requires the identification of the energy of each photon as well as accurate counting of photons in each energy bins. The latter is done by the single-photon counting(SPC) algorithm, which takes the images as input and returns the positions of the photons identified;the former is achieved by making use of Bragg's law,\n",
    "\n",
    "$$\n",
    "    n \\frac{hc}{E}=2d \\sin\\theta\n",
    "$$\n",
    "\n",
    "which associates the photon energy $E$ with the deflection angle $\\theta$. Thus, by deflecting the emitted photons using crystals with known lattice spacing $2d$, we are able to set up a one-to-one correspondence between the position of the photon on the CCD camera and its energy, using the geometry of the experiment which can be extracted from the information on the CCD images. \n",
    "\n",
    "The major difficulties in the previous approach are presented by the presence of background noise and multi-photon events(MPE). The fluctuation of background noise may result in the identification of spurious events, whereas the presence of MPE, entangled clusters due to more than one photon, making it hard to determine the actual positions of each photon. \n",
    "\n",
    "This notebook is organized in the following way: in the first part, after importing the data, we present the SPC algorithm, making use of the gradient descent method; we also present an algorithm to eliminate the spurious events due to the fluctuation of noise, by maintaining that the number of electron-hole pairs created by photons, and thus the total brightness it created, must obeys Gaussian distribution, and thus the spurious events can be identified and eliminated. In the second part, using the result of the SPC section, We present methods to identify the spectral lines, and use the energy values of them known to us to determine the geometry, and in the end plot the spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4200f9f",
   "metadata": {},
   "source": [
    "## Module importation\n",
    "\n",
    "At the beginning, the program imports the module required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import h5py\n",
    "import itertools\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.stats import logistic\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import mode\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import leastsq\n",
    "from scipy.optimize import fsolve\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from statistics import mean\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108f388",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "\n",
    "Imports the data in hdf5 format, and generate some basic information of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea065d",
   "metadata": {},
   "source": [
    "\n",
    "<b><u>Enter the path of the data file here:</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_address = \"sxro6416-r0504.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277370e8",
   "metadata": {},
   "source": [
    "<i>NB: This part of the code is provided by the supervisor at the beginning of the project.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_images(f_name):\n",
    "    \n",
    "    # Name of the hdf file that contain the data we need\n",
    "    # Open the hdf5 file, use the path to the images to extrate the data and place\n",
    "    # it in the image data object for further manipulation and inspection.\n",
    "    datafile = h5py.File(f_name, 'r')\n",
    "    image_data = []\n",
    "    for i in itertools.count(start=0):\n",
    "        d = datafile.get(f'Configure:0000/Run:0000/CalibCycle:{i:04d}/Princeton::FrameV2/SxrEndstation.0:Princeton.0/data')\n",
    "        if d is not None:\n",
    "            # actual image is at first index\n",
    "            image_data.append(d[0])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Tell me how many images were contained in the datafile\n",
    "    print(f\"Loaded {len(image_data)} images\")\n",
    "\n",
    "    return image_data\n",
    "\n",
    "image_data = import_images(hdf5_file_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e2ff1",
   "metadata": {},
   "source": [
    "We have imported an array of images, each of them having dimensions $2048\\times2048$ and entries between 0 and a few hundreds, representing the intensity value, or ADU value, of each pixel of the CCD camera. To have a look of the images, we plot one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd86186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the size of the plot used in this notebook\n",
    "plt.rcParams[\"figure.figsize\"]=[12, 12];\n",
    "plt.yticks(fontsize = 15);\n",
    "plt.xticks(fontsize = 15);\n",
    "\n",
    "plt.imshow(image_data[1])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c9a6f",
   "metadata": {},
   "source": [
    "Plot the histogram of the ADU value of each pixels in one of the images in `image_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(image_data[1].flatten(), bins = 150);\n",
    "plt.yscale('log')\n",
    "plt.xlim([0,400]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c195659",
   "metadata": {},
   "source": [
    "From the above histagram, we are able to see the large pedestal, a normal-distributed peak on the left around $\\mathrm{ADU}=50$ representing the background noise, and the signals on the right corresponding to photon events. We also identify some spurious bright spots in the image with too large ADU values; these will be filtered in the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903708f",
   "metadata": {},
   "source": [
    "## Single Photon Counting\n",
    "\n",
    "The SPC algorithm is build on the assumption that each photon event is associated with a 2-dimensional Gaussian distribution\n",
    "$$\n",
    "    I(x,y)=\\frac{A}{\\sigma_x \\sigma_y }\\exp\\left(-\\frac{(x-x_0)^2}{2\\sigma_x^2}-\\frac{(y-y_0)^2}{2\\sigma_y^2}\\right)\n",
    "$$\n",
    "and that the increment in the ADU value of each pixel is given by the integration of such a distribution within:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{ADU_G}(i,j)&=\\int_i^{i+1}\\int_j^{j+1}I(x,y)\\mathrm{d}y\\mathrm{d}x\n",
    "    \\\\\n",
    "    &=\\frac{\\pi}{2}A\\left[\\mathrm{erf}\\left(\\frac{i+1-x0}{\\sqrt{2}\\sigma_x}\\right)-\\mathrm{erf}\\left(\\frac{i-x0}{\\sqrt{2}\\sigma_x}\\right)\\right]\\left[\\mathrm{erf}\\left(\\frac{j+1-y0}{\\sqrt{2}\\sigma_y}\\right)-\\mathrm{erf}\\left(\\frac{j-y0}{\\sqrt{2}\\sigma_y}\\right)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore, our algorithm should find the peaks of ADU values in the image, identify a Gaussian distrubition that best resembles the entries around it and return the parameters $x_0,y_0,\\sigma_x,\\sigma_y,A$. This is achieved by the SPC algorithm, which takes each image in `image_data` as input and returns the position and the intensity of the photon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74ed73",
   "metadata": {},
   "source": [
    "### Step 0: Creating a demo data\n",
    "\n",
    "A demo data, saved in `demo_data.csv`, is used to demonstrate how the SPC algorithm works.\n",
    "\n",
    "It is the portion `[492:525, 1308:1340]` of the second image provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b7e9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the demo data, convert it in to a numpy array\n",
    "demo_data = []\n",
    "with open('demo_data.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        demo_data.append(list(map(int, list(row))))\n",
    "demo_data = np.array(demo_data)\n",
    "\n",
    "# Plot the demo data\n",
    "plt.imshow(demo_data)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a623996",
   "metadata": {},
   "source": [
    "### Step 1: Image normalisation\n",
    "\n",
    "<u>Goal of this step:</u> Normalise the images, so as to set the mean of the pedestals and thus the noise contribution to be 0.\n",
    "\n",
    "Since it is found that in some images, the bottom is brighter than the top, image normalisation is done by cutting the image horizontally into `norm_cut_num` strips, with each strip having a height of `2048/norm_cut_num`, and subtracting each entry in the strip with the mode of the strip. This guarantees that the mode of the Gaussian background noise is set to 0 throughout the image. From the properties of Gaussian distributions, this also guarantees that the mean goes to 0. <i>NB: The demo data have been normalised in such a way.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a39ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the number of strips to cut\n",
    "norm_cut_num = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_normalisation(im, cut_num):\n",
    "    \n",
    "    # Input: the image; the number of strips to cut\n",
    "    # Output: the normalised image\n",
    "    \n",
    "    # Make a copy of the input data, using the deepcopy function to ensure that im remains unchanged:\n",
    "    dat = deepcopy(im.astype(int))\n",
    "    # NB: astype(int) is added to convert the entries of im from unsigned int (0-65536) to signed int.\n",
    "    \n",
    "    # Make sure that cut_num is a factor of the size of the image, i.e. 2048. If not, raise an error.\n",
    "    try:\n",
    "        cut_height = int(2048/cut_num)\n",
    "        if(cut_height * cut_num != 2048):\n",
    "            raise ValueError('Invalid norm_cut_num')\n",
    "    except ValueError as e:\n",
    "        print('Error: ', e)\n",
    "    \n",
    "    # Normalise the image\n",
    "    for i in range(32):\n",
    "        # Find the mode of the strip; if multiple modes are found, select the minimum of them\n",
    "        im_mode = min(mode(dat[i*64:(i+1)*64,:].flatten())[0])\n",
    "        \n",
    "        dat[i*64:(i+1)*64,:] = dat[i*64:(i+1)*64,:].astype(int) - im_mode\n",
    "    \n",
    "    return dat\n",
    "\n",
    "\n",
    "# Applying this function to our image_data\n",
    "for i in range(len(image_data)):\n",
    "    image_data[i] = image_normalisation(image_data[i], norm_cut_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f865db",
   "metadata": {},
   "source": [
    "Checking the norm of the pedestal has been set to 0 by plotting the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b06da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(image_data[1].flatten(), bins = 150);\n",
    "plt.yscale('log')\n",
    "plt.xlim([-50,350]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca8800",
   "metadata": {},
   "source": [
    "The algorithm then sets the pixels near the boundaries to be 0, as it is noticed that pixels near the boundaries may have different ADU values, potentially due to instrumental error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429afa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_setting(im):\n",
    "    \n",
    "    # Input: a normalised image\n",
    "    # Output: the image, with the entries near the edges set to 0\n",
    "    \n",
    "    # Find the height and width of im\n",
    "    h = im.shape[0]\n",
    "    w = im.shape[1]\n",
    "    \n",
    "    dat = deepcopy(im.astype(int))\n",
    "    \n",
    "    # Set the entries near the boundary to 0\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if((i < 2 or i > h - 2) or (j < 4 or j > w - 2)):\n",
    "                dat[i, j]=0\n",
    "                \n",
    "    return dat\n",
    "\n",
    "# Applying this function to our normalised image_data\n",
    "for i in range(len(image_data)):\n",
    "    image_data[i] = boundary_setting(image_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0a3c2",
   "metadata": {},
   "source": [
    "### Step 2: Thresholding & box assignment\n",
    "\n",
    "<u>Goal of this step:</u> Split each image into small portions that can be considered separately.\n",
    "\n",
    "We assume that each photon event can only have have influence in the surrounding pixels; pixels having a distance greater than 2px cannot be influenced. Hence, if one photon or a set of photons is separated by a distance of at least 2px from all other photons, we can single it/them out to be analysed separately.\n",
    "\n",
    "Using this, the algorithm in this step (1) Applies a threshold to the images, to find the pixels with large ADUs; (2) Assign rectangular 'boxes' to enclose the large-ADU pixels and its surroundings, making sure that (i) events in different boxes are separated and do not have influence on each other and (ii) if there are more than one events in one box, then these events are entangled. The contents within these boxes are going to be considered separately when, in the next step, exact positions of the photon events are to be found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e6988",
   "metadata": {},
   "source": [
    "#### 2.1 Thresholding\n",
    "\n",
    "We select the threshold value to be 30; this allows most photon events and at the same time a small portion of noises. The noise-cancelling algorithm is presented in step 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e878df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold:\n",
    "thres = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98399467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The thresholding algorithm.\n",
    "\n",
    "def thresholding(data, threshold):\n",
    "    \n",
    "    # Input: a normalised image\n",
    "    # Output: A matrix, having the same dimensions of the input image, with each entry being 0 if the corresponding entry in the input \n",
    "    #         matrix is < threshold, and 1 if it's >= threshold\n",
    "    \n",
    "    def compare(val):\n",
    "        if(val >= threshold):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    label_matrix = [[compare(data[i, j]) for j in range(data.shape[1])] for i in range(data.shape[0])]\n",
    "    \n",
    "    return label_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1accc37d",
   "metadata": {},
   "source": [
    "Applying it on our cute little demo data: \n",
    "\n",
    "Yellow pixels are entries greater than threshold and purple pixels are other entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_label_matrix = thresholding(demo_data, thres)\n",
    "plt.imshow(demo_label_matrix)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75992753",
   "metadata": {},
   "source": [
    "#### 2.2 Box assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf147875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a class of box, containing the coordinate of the edges, as well as the width and height of it.\n",
    "\n",
    "class box:\n",
    "    'used to enclose photon events'\n",
    "    \n",
    "    def __init__(self, xmin, ymin, xmax, ymax):\n",
    "        self.x_min = xmin\n",
    "        self.y_min = ymin\n",
    "        self.x_max = xmax\n",
    "        self.y_max = ymax\n",
    "        \n",
    "        self.width = xmax - xmin + 1\n",
    "        self.height = ymax - ymin + 1\n",
    "    \n",
    "    def params(self):\n",
    "        # Return the parameters of the box\n",
    "        return [self.x_min, self.y_min, self.x_max, self.y_max]\n",
    "    \n",
    "    def hw(self):\n",
    "        # Find the shape of the box\n",
    "        return [self.height, self.width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfdef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The box assignment function\n",
    "\n",
    "def boxing(thres_matrix, output = 'None'):\n",
    "    \n",
    "    # Input: the threshold matrix, coming from the thresholding() function\n",
    "    # Output: A list of boxes identified within the image. \n",
    "    \n",
    "    # The 'output' parameter determines whether the function prints some information for \n",
    "    # debugging or demonstration purposes.\n",
    "    \n",
    "    # Create a copy of the input matrix, so that it will not be changed\n",
    "    m = np.array(deepcopy(thres_matrix))\n",
    "    \n",
    "    # Initialise the box list\n",
    "    box_list = []\n",
    "    \n",
    "    #Prepare for plotting the dataset, if needed\n",
    "    if(output != 'None'):\n",
    "        fig, ax = plt.subplots(1)\n",
    "                               \n",
    "    # Search for entry 1's in the input matrix\n",
    "    for i in range(m.shape[0]):\n",
    "         for j in range(m.shape[1]):\n",
    "            if(m[i, j] == 1):\n",
    "                # An entry 1 is found: firstly, the box only contains this entry and its surrounding 3*3.\n",
    "                x = i\n",
    "                y = j\n",
    "                \n",
    "                x_min = x - 1\n",
    "                y_min = y - 1\n",
    "                x_max = x + 1\n",
    "                y_max = y + 1\n",
    "                \n",
    "                # Search for if there is any more entry 1's in the surrounding 5*5:\n",
    "                while(True):\n",
    "                    # Flag identifying the presence of entry 1's\n",
    "                    flag = 0\n",
    "                    \n",
    "                    # Set the current entry to 0, in order to avoid double counting\n",
    "                    m[x, y] = 0\n",
    "                    \n",
    "                    for ii in range(x_min - 1, x_max + 2):\n",
    "                        for jj in range(y_min - 1, y_max + 2):\n",
    "                            # Check if the search has reached the boundary of the image; if so, skips.\n",
    "                            if((ii >= m.shape[0]) or (jj >= m.shape[1])): \n",
    "                                continue\n",
    "                            \n",
    "                            elif(m[ii, jj] == 1): # More entry 1's are found\n",
    "                                flag = 1\n",
    "                                \n",
    "                                # Set this entry to 0, in order to avoid double counting\n",
    "                                m[ii, jj] = 0\n",
    "                                \n",
    "                                # Enlarge the box to accommodate all these entries found in this way,\n",
    "                                # as they are assumed to be entangled and must be considered simultaneously\n",
    "                                x_min = min(x_min, ii - 1)\n",
    "                                y_min = min(y_min, jj - 1)\n",
    "                                x_max = max(x_max, ii + 1)\n",
    "                                y_max = max(y_max, jj + 1)\n",
    "                                \n",
    "                    # this searching process must be iterated until no more entry 1's are found \n",
    "                    # in the box's ambiance, and that it is safe to consider the elements whthin \n",
    "                    # this box separately.\n",
    "                    if(flag == 0):\n",
    "                        break\n",
    "                \n",
    "                #Append our box identified to the box list\n",
    "                b = box(x_min, y_min, x_max, y_max)\n",
    "                box_list.append(b)\n",
    "                \n",
    "                # Generate output, if needed\n",
    "                if(output != 'None'):\n",
    "                    print('box created containing [%d:%d, %d:%d]' % (x_min, x_max, y_min, y_max))\n",
    "                    \n",
    "                    # Add a rectangle representing this box to the plot\n",
    "                    box_rect = patches.Rectangle((y_min - 0.5, x_min - 0.5), b.hw()[0], b.hw()[1],\n",
    "                                                 linewidth = 1, edgecolor = 'r', facecolor = \"none\")\n",
    "                    ax.add_patch(box_rect)\n",
    "\n",
    "    # Generate output, if needed\n",
    "    if(output != 'None'):\n",
    "        plt.imshow(thres_matrix)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    return box_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba49639",
   "metadata": {},
   "source": [
    "Applying it on our beloved demo data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_box_list = boxing(demo_label_matrix, output = 'Yes please!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfea4a",
   "metadata": {},
   "source": [
    "### Step 3: Locating the exact photon position and intensity within each box using gradient descent method\n",
    "\n",
    "<u>Goal of this step</u>: within each box, find the set of parameters $x_0,y_0,\\sigma_x,\\sigma_y,A$ for each photon that yields the least square error\n",
    "\n",
    "$$\n",
    "    \\mathrm{error}=\\sum_{i,j}(\\mathrm{ADU}(i,j)-\\mathrm{ADU_G}(i,j))^2\n",
    "$$\n",
    "where $\\mathrm{ADU}(i,j)$ is the ADU value after normalisation.\n",
    "\n",
    "This optimisation task is done by the gradient descent method. First, find the number of photons within each box, and an initial estimation of their parameters. Then, use the gradient descent method to optimise the parameters until convergence is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e49d3",
   "metadata": {},
   "source": [
    "#### 3.1 Preparation\n",
    "\n",
    "We start by defining two constants, $\\pi$ and $\\sqrt{2}$, which will be frequently used in the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi = np.pi\n",
    "Sqrt2 = np.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2107211",
   "metadata": {},
   "source": [
    "We also define an array containing values of error functions($\\mathrm{erf}$) of -10 to 10 that will be frequently evaluated in the calculations.\n",
    "\n",
    "This array, `Erf`, satisfies: for an integer $x$ with $-10^6\\le x\\le 10^6$, \n",
    "$$\n",
    "    \\mathtt{Erf[x]} = \\mathrm{erf}\\left(\\frac{x}{10^5}\\right)\n",
    "$$\n",
    "where negative entries means counting backward as usual. Since the difference between $\\mathrm{erf}(10)$ and 1(as well as $\\mathrm{erf}(-10)$ and -1) is neglegible, we are able to use the value of $\\mathrm{erf}(10)$ to replace error functions of values greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "Erf = []\n",
    "for i in range(10**6 + 1):\n",
    "    Erf.append(math.erf(i / 10**5))\n",
    "for i in range(-10**6 , 0):\n",
    "    Erf.append(math.erf(i / 10**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f607918c",
   "metadata": {},
   "source": [
    "The algorithm first establishing a class of photon events(PE), containing the five parameters characterising it, namely $x_0,y_0,\\sigma_x,\\sigma_y,A$, as well as the width and height of the box in which it lives. It moreover contains the theoretical ADU value, $\\mathrm{ADU}_\\mathrm{G}$, caused by this photon alone. The actual theoretical ADU value is the linear superpositions of contributions from each photon.\n",
    "\n",
    "Recall that $\\mathrm{ADU}_\\mathrm{G}$ is given by:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathrm{ADU_G}(i,j)&=\\int_i^{i+1}\\int_j^{j+1}I(x,y)\\mathrm{d}y\\mathrm{d}x\n",
    "    \\\\\n",
    "    &=\\frac{\\pi}{2}A\\left[\\mathrm{erf}\\left(\\frac{i+1-x0}{\\sqrt{2}\\sigma_x}\\right)-\\mathrm{erf}\\left(\\frac{i-x0}{\\sqrt{2}\\sigma_x}\\right)\\right]\\left[\\mathrm{erf}\\left(\\frac{j+1-y0}{\\sqrt{2}\\sigma_y}\\right)-\\mathrm{erf}\\left(\\frac{j-y0}{\\sqrt{2}\\sigma_y}\\right)\\right]\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that calculates the part within the square bracket of the above expression:\n",
    "def entry(i, x0, s):\n",
    "    \n",
    "    # Calculate the variable in the first and second pairs of parentheses, applying bounds of [-10, 10] to it from reasons\n",
    "    # discussed above\n",
    "    var_1 = max(-10, min(10, (-x0 + i + 1) / (Sqrt2 * s)))\n",
    "    var_2 = max(-10, min(10, (-x0 + i ) / (Sqrt2 * s)))\n",
    "    \n",
    "    # Convert the variables calculated into array indices for Erf[], and obtain the final value\n",
    "    \n",
    "    i1 = math.floor(var_1 * 100000)\n",
    "    i2 = math.floor(var_2 * 100000)\n",
    "    \n",
    "    return Erf[i1] - Erf[i2]\n",
    "\n",
    "class photon_event:\n",
    "    'A photon event, the box in which it lives, and the ripple of ADU values it creates'\n",
    "    \n",
    "    def __init__(self, y0, x0, sx, sy, w, h, A):\n",
    "\n",
    "        self.x0 = x0\n",
    "        self.y0 = y0\n",
    "        self.sx = sx\n",
    "        self.sy = sy\n",
    "        self.A = A\n",
    "        \n",
    "        # Width and height of the box\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        \n",
    "        # Generate the distribution matrix, ADU_G of the photon. \n",
    "        ls1=[entry(i, x0, sx) for i in range(w)]\n",
    "        ls2=[entry(j, y0, sy) for j in range(h)]\n",
    "        self.dist_matrix=1/2 * Pi * self.A * np.outer(ls1, ls2)\n",
    "\n",
    "    # A function returning the five parameters of the photon \n",
    "    def params(self):\n",
    "        return [self.x0, self.y0, self.sx, self.sy, self.A]\n",
    "    \n",
    "    # A function to change the parameter of the photon itself, but not the box\n",
    "    def new_value(self, para_ls):\n",
    "        \n",
    "        self.x0, self.y0, self.sx, self.sy, self.A = para_ls\n",
    "        \n",
    "        # Alter the distribution matrix, ADU_G of the photon. \n",
    "        ls1=[entry(i, self.x0, self.sx) for i in range(self.w)]\n",
    "        ls2=[entry(j, self.y0, self.sy) for j in range(self.h)]\n",
    "        self.dist_matrix=1/2 * Pi * self.A * np.outer(ls1, ls2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c722a",
   "metadata": {},
   "source": [
    "Define the error function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(pe_array, box_dat):\n",
    "    \n",
    "    # Input: a list of photon_event objects, as well as the data in the box containing these photons and them only\n",
    "    # Output: the error in this box\n",
    "    \n",
    "    # Find ADU_G, which is the linear superpositions of contributions from each photon\n",
    "    tot_dist_matrix = sum([event.dist_matrix for event in pe_array])\n",
    "    \n",
    "    # Return the total error\n",
    "    return sum(((box_dat - tot_dist_matrix)**2).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825cf70",
   "metadata": {},
   "source": [
    "The algorithm treats boxes with one photon event and boxes with more than one photon events differently. We need a criterion to classify the boxes at the initial stage. The criterion is as follows: if a box's height and width are both $\\le4$, we classify this as a single photon event(SPE); otherwise, it is treated as a multi photon event(MPE), since, as described above, no single photon can extend its influence beyond 4 pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40489d",
   "metadata": {},
   "source": [
    "#### 3.2 Gradient descent: SPEs\n",
    "\n",
    "We define the gradient descent optimisation function for single-photon events, which contains the following parts:\n",
    "\n",
    "<b>Determination of initial values:</b>\n",
    "We select the initial values for the SPE algorithm as follows: \n",
    "\n",
    "The initial `x0, y0` is select to be the mass center of the data\n",
    "$$\n",
    "    \\mathtt{x0}^\\mathrm{ini} = \\frac{\\sum_{i,j} \\mathtt{dat[i, j]} \\times \\mathtt{i}}{\\sum_{i,j} \\mathtt{dat[i, j]}} \\mathtt{ + 0.5}\n",
    "$$\n",
    "$$\n",
    "    \\mathtt{y0}^\\mathrm{ini} = \\frac{\\sum_{i,j} \\mathtt{dat[i, j]} \\times \\mathtt{j}}{\\sum_{i,j} \\mathtt{dat[i, j]}} \\mathtt{ + 0.5}\n",
    "$$\n",
    "\n",
    "where `dat` is the data inside the box. If this results in a coordinate that is outside of the box, we instead select it to be at the center of the pixel with maximum ADU value. \n",
    "\n",
    "The initial `sx, sy` is selected to be \n",
    "$$\n",
    "    \\mathtt{sx^{\\mathrm{ini}} = 0.2 + 0.2}\\times \\frac{\\mathtt{dat[im + 1, jm] + dat[im - 1, jm]}}{\\mathtt{dat[im, jm]}}\n",
    "$$\n",
    "$$\n",
    "    \\mathtt{sy^{\\mathrm{ini}} = 0.2 + 0.2}\\times \\frac{\\mathtt{dat[im, jm + 1] + dat[im, jm - 1]}}{\\mathtt{dat[im, jm]}}\n",
    "$$\n",
    "where `im, jm` is the coordinate of the maximum entry.\n",
    "\n",
    "The initial `A` is selected randomly between $22$ and $25$.\n",
    "\n",
    "<b>Gradient descent:</b>\n",
    "Using these initial values, the program starts a loop to alter them until a minimum of the error function is reached. Within each iteration, gradient descent is completed using the `descent` function, defined below, which updates the photon parameters by checking the change of error when each of them are shifted by a small amount. After this we check if convergence is reached by finding the difference between the current error and the error `iter_diff` iterations earlier, and compare it with `err * conv_crit`. \n",
    "\n",
    "<b>Final check: had we mistaken an MPE with an SPE?</b> \n",
    "    If the box has size $3\\times3$ or $3\\times4$ then this is unlikely; moreover, even if there are two photons, it is likely that the photon we found using the SPE algorithm has an intensity equals to the combination of them. For $4\\times4$ boxes a check need to be added: if, upon convergence, the error is still greater than `err_max`, this box will be processed instead by the MPE algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24648db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the step length for each parameters\n",
    "step_x = 0.01\n",
    "step_y = 0.01\n",
    "step_sx = 0.005\n",
    "step_sy = 0.005\n",
    "step_A = 0.3\n",
    "\n",
    "# Set the descent factor: a factor to be multiplied when deciding the amount of change of parameters in each iteration\n",
    "descent_factor = 0.2\n",
    "\n",
    "# We require the standard errors to be bounded; define the minimum and maximum allowed values:\n",
    "s_min = 0.2\n",
    "s_max = 0.6\n",
    "\n",
    "# Set the other parameters described above\n",
    "iter_diff = 10\n",
    "conv_crit = 1/40\n",
    "err_max = 1600\n",
    "\n",
    "# Set the miximum number of iterations\n",
    "max_iter = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent(pe_ls, step_ls, dat):\n",
    "    \n",
    "    # Input: a list of photon events; the list of their step lengths; the data within the box considered.\n",
    "    # Output: the updated list of parameters.\n",
    "    \n",
    "    # Calculate the photon number and the total error\n",
    "    photon_n = len(pe_ls)\n",
    "    err = error(pe_ls, dat)\n",
    "    \n",
    "    # The list of new parameters\n",
    "    new_param_ls = []\n",
    "    \n",
    "    for n in range(photon_n):\n",
    "        # Read the parameters of the current photon\n",
    "        param = pe_ls[n].params()\n",
    "        \n",
    "        # Create five lists, in each of which one parameter is altered by its step length\n",
    "        new_params = param + np.diag(step_ls)\n",
    "        \n",
    "        # Create the array storing the error differences and calculate the values of them.\n",
    "        # NB for efficiency purposes a for loop is not used.\n",
    "        err_diff = np.zeros(5)\n",
    "        \n",
    "        pe_ls[n].new_value(new_params[0])\n",
    "        err_diff[0] = error(pe_ls, dat) - err\n",
    "        \n",
    "        pe_ls[n].new_value(new_params[1])\n",
    "        err_diff[1] = error(pe_ls, dat) - err\n",
    "        \n",
    "        pe_ls[n].new_value(new_params[2])\n",
    "        err_diff[2] = error(pe_ls, dat) - err\n",
    "        \n",
    "        pe_ls[n].new_value(new_params[3])\n",
    "        err_diff[3] = error(pe_ls, dat) - err\n",
    "        \n",
    "        pe_ls[n].new_value(new_params[4])\n",
    "        err_diff[4] = error(pe_ls, dat) - err\n",
    "        \n",
    "        # Generate the updated parameters\n",
    "        # NB parameters are shifted in this way by an amount proportional to descent_factor, the gradient, and\n",
    "        # the SQUARE of the step length. This is to accommodate the different ranges of them(e.g. some 0.1s for\n",
    "        # sx and sy but 0-100 for A)\n",
    "        new_param_ls.append(-np.array(step_ls) * descent_factor * err_diff + param)\n",
    "        \n",
    "        # Check if the standard errors and intensities are within boundary\n",
    "        new_param_ls[n][2] = max(s_min, min(s_max, new_param_ls[n][2]))\n",
    "        new_param_ls[n][3] = max(s_min, min(s_max, new_param_ls[n][3]))\n",
    "        new_param_ls[n][4] = max(0, new_param_ls[n][4])\n",
    "    \n",
    "    return new_param_ls, err\n",
    "\n",
    "step_ls = [step_x, step_y, step_sx, step_sy, step_A]\n",
    "\n",
    "def gradient_descent_single(b, image_data, output = 'None'):\n",
    "    \n",
    "    # Input: a box classified as SPE, and the image data in which it lives\n",
    "    # Output: the five parameters of the photon, and a boolean flag checking if we have mistaken an MPE as an SPE.\n",
    "    \n",
    "    # The 'output' parameter determines whether the function prints some information for \n",
    "    # debugging or demonstration purposes.\n",
    "    \n",
    "    # Generate the box data\n",
    "    xmin, ymin, xmax, ymax = b.params()\n",
    "    xmax = xmax + 1\n",
    "    ymax = ymax + 1\n",
    "    dat = np.array(image_data[xmin:xmax, ymin:ymax])\n",
    "    \n",
    "    # Generate output, if needed\n",
    "    if(output != 'None'):\n",
    "        print('Box data:')\n",
    "        print(dat)\n",
    "    \n",
    "    # Generate initial x0, y0\n",
    "    xavg = 0\n",
    "    yavg = 0\n",
    "    for i in range(dat.shape[0]):\n",
    "        for j in range(dat.shape[1]):\n",
    "            xavg = xavg + i * dat[i, j]\n",
    "            yavg = yavg + j * dat[i, j]\n",
    "    \n",
    "    x = xavg / max(sum(dat.flatten()), 1) + 0.5\n",
    "    y = yavg / max(sum(dat.flatten()), 1) + 0.5\n",
    "    \n",
    "    h, w = b.hw()\n",
    "    # Check if the initial condition determined in such a way is erroneous; if so, use the alternative method\n",
    "    # and select x, y to be at the center of the pixel with maximum entry \n",
    "    [i0, i1] = np.unravel_index(dat.argmax(), dat.shape)\n",
    "    if(x < 0 or x > h or y < 0 or y > w):\n",
    "        x = i0 + 0.5\n",
    "        y = i1 + 0.5\n",
    "    \n",
    "    # sx and sy are required to be bounded between smin and smax\n",
    "    s_x = min(max(0.2 + 0.2 * (dat[i0 + 1, i1] + dat[i0 - 1, i1]) / dat[i0, i1], s_min), s_max)\n",
    "    s_y = min(max(0.2 + 0.2 * (dat[i0, i1 + 1] + dat[i0, i1 - 1]) / dat[i0, i1], s_min), s_max)\n",
    "    \n",
    "    # Generate initial A\n",
    "    A = 22 + np.random.uniform() * 3\n",
    "    \n",
    "    # Generate the photon event\n",
    "    spe = photon_event(y, x, s_x, s_y, w, h, A)\n",
    "    if(output != 'None'):\n",
    "        print('Initial guesses of the parameters are: \\n x=%f, y=%f, sx=%f, sy=%f, A=%f' %(x, y, s_x, s_y, A))\n",
    "        print('with a distribution matrix of:')\n",
    "        print(spe.dist_matrix.astype(int))\n",
    "    # Generate the list of parameters and steps\n",
    "    para_ls = [[x, y, s_x, s_y, A]]\n",
    "    \n",
    "    # Create an array to store the errors of each step\n",
    "    err_array = []\n",
    "    \n",
    "    if(output != 'None'):\n",
    "        print('-----------Iteration starts-------------')\n",
    "        \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        # Use descent to obtain the new parameters and the current error, and add the latter to err_array\n",
    "        new_param_ls, err = descent([spe], step_ls, dat)\n",
    "        err_array.append(err)\n",
    "        \n",
    "        # Alter the photon event\n",
    "        spe.new_value(new_param_ls[0])\n",
    "        para_ls[0] = spe.params()\n",
    "        \n",
    "        if(output != 'None' and i%10 == 0):\n",
    "            # Print the parameters every 10 iterations\n",
    "            print('Iteration #%d: x=%f, y=%f, sx=%f, sy=%f, A=%f' %\n",
    "                  (i + 1, para_ls[0][0], para_ls[0][1], para_ls[0][2], para_ls[0][3], para_ls[0][4]))\n",
    "            print('Current error:%f' % err)\n",
    "        \n",
    "        # Check if convergence is reached\n",
    "        if(i >= iter_diff and err_array[i - iter_diff] - err <= err * conv_crit):\n",
    "            if(output != 'None'):\n",
    "                print('Convergence reached at iteration #%d: x=%f, y=%f, sx=%f, sy=%f, A=%f' %\n",
    "                  (i + 1, para_ls[0][0], para_ls[0][1], para_ls[0][2], para_ls[0][3], para_ls[0][4]))\n",
    "                print('Current error:%f' % err)\n",
    "                print('-----------Iteration ends-------------')\n",
    "                print('Final distribution matrix:')\n",
    "                print(spe.dist_matrix.astype(int))\n",
    "            break\n",
    "\n",
    "    # Postprocessing: check if we've mistaken an MPE as an SPE\n",
    "    flag = 0 \n",
    "    if(b.hw() == [4,4] and err > err_max):\n",
    "        flag = 1\n",
    "    \n",
    "    x, y, s_x, s_y, A = para_ls[0]   \n",
    "    return [x, y, s_x, s_y, A, flag]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd33ec1",
   "metadata": {},
   "source": [
    "As an example, apply the algorithm to one of the boxes in the demo data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent_single(demo_box_list[11], demo_data, output = 'yes please');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff8f83",
   "metadata": {},
   "source": [
    "#### 3.3 Gradient descent: MPEs\n",
    "\n",
    "The gradient descent optimisation function for multi-photon events contains the following parts:\n",
    "\n",
    "<b>Determination of initial values and initial guess of photon numbers within:</b>\n",
    "As an initial guess, we place a photon event with `sx = 0.4, sy = 0.4` and `A` randomly selected between 22 and 25 at the center of each pixel which (i) is above `thres`, and (ii) is greater than all eight adjacent pixels.\n",
    "\n",
    "<b>Gradient descent #1:</b>\n",
    "Run a gradient descent until convergence is reached.\n",
    "\n",
    "<b>Attempts to add more photons in this box:</b>\n",
    "If, upon subtracting the actual data with the distribution matrix of each photon, the remainder, named `dat_res`, is examined: if (i) there is one entry greater than `thres`, or (ii) there are two entries greater than `thres - 10`, then it is attempted to add one more photon event at the center of the pixel with maximum entry in `dat_res`. We then compare the error to the previous error and decide if we take the new arrangement, and if so, the above process is iterated until conditions are not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum # of photons allowed in each event:\n",
    "max_photon = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_multi(b, image_data, output = 'None'):\n",
    "    \n",
    "    # Input: a box classified as MPE, and the image in which it lives\n",
    "    # Output: the five parameters of the photon, and a boolean flag checking if we have mistaken an MPE as an SPE.\n",
    "    \n",
    "    # The 'output' parameter determines whether the function prints some information for \n",
    "    # debugging or demonstration purposes.\n",
    "    \n",
    "    # Generate the box data\n",
    "    xmin, ymin, xmax, ymax = b.params()\n",
    "    xmax = xmax + 1\n",
    "    ymax = ymax + 1\n",
    "    dat = np.array(image_data[xmin:xmax, ymin:ymax])\n",
    "        \n",
    "    # Generate output, if needed\n",
    "    if(output != 'None'):\n",
    "        print('Box data:')\n",
    "        print(dat)\n",
    "        \n",
    "    # ------------Stage 1: initial guess of photon numbers and parameters, gradient descent #1--------------\n",
    "    \n",
    "    # Initialise the photon number, the positions of photons and the intensities\n",
    "    photon_n = 0\n",
    "    x = np.array([])\n",
    "    y = np.array([])\n",
    "    sx = np.array([])\n",
    "    sy = np.array([])\n",
    "    A = np.array([])\n",
    "    \n",
    "    # Initialise the list of photon events\n",
    "    pe_array = []\n",
    "    \n",
    "    h, w = b.hw()\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            if(dat[i, j] >= thres):\n",
    "                if(i == 0 or i == w - 1 or j == 0 or j == h - 1):\n",
    "                    # Check if, erroneously, there is a pixel >=30 at the boundary of the box (due to errors in the boxing process);\n",
    "                    # if so, set this to 0\n",
    "                    dat[i, j] = 0\n",
    "                elif(dat[i, j] >= \n",
    "                     max(dat[i + 1, j] - 1, #The -1 here and below is to prevent double counting if there exists two equal maxima\n",
    "                         dat[i - 1 ,j],\n",
    "                         dat[i, j + 1] - 1,\n",
    "                         dat[i, j - 1],\n",
    "                         dat[i + 1, j + 1] - 1,\n",
    "                         dat[i + 1, j - 1] - 1,\n",
    "                         dat[i - 1, j - 1],\n",
    "                         dat[i - 1, j + 1])):\n",
    "                    photon_n = photon_n + 1\n",
    "                    x = np.append(x, i + 0.5)\n",
    "                    y = np.append(y, j + 0.5)\n",
    "                    sx = np.append(sx, 0.4)\n",
    "                    sy = np.append(sy, 0.4)\n",
    "                    A_init = 22 + np.random.uniform() * 3\n",
    "                    A = np.append(A, A_init)\n",
    "                    \n",
    "                    pe = photon_event(j + 0.5, i + 0.5, 0.4, 0.4, w, h, A_init)\n",
    "                    pe_array.append(pe)\n",
    "                    \n",
    "                    # Generate output, if needed\n",
    "                    if(output != 'None'):\n",
    "                        print('Photon created at x=%g, y=%g' % (pe.x0, pe.y0))\n",
    "    \n",
    "    if(output != 'None'):\n",
    "        print('%d photon(s) initialised.' % photon_n)\n",
    "        print('----------Initial iteration starts----------')\n",
    "        \n",
    "    para_ls = np.transpose([x, y, sx, sy, A])\n",
    "    err_array = []\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        # Use descent to obtain the new parameters and the current error, and add the latter to err_array\n",
    "        new_param_ls, err = descent(pe_array, step_ls, dat)\n",
    "        err_array.append(err)\n",
    "\n",
    "        # Change the parameters of the photons\n",
    "        for n in range(photon_n):\n",
    "            pe_array[n].new_value(new_param_ls[n])\n",
    "            para_ls[n] = new_param_ls[n]\n",
    "            if(output != 'None' and i%10 == 0):\n",
    "                # Print the parameters every 10 iterations\n",
    "                print('Iteration #%d: photon no. %d has x=%f, y=%f, sx=%f, sy=%f, A=%f' %\n",
    "                    (i + 1, n + 1, para_ls[n][0], para_ls[n][1], para_ls[n][2], para_ls[n][3], para_ls[n][4]))\n",
    "            \n",
    "        # Check if convergence is reached\n",
    "        if(i >= iter_diff and err_array[i - iter_diff] - err <= err * conv_crit):\n",
    "            if(output != 'None'):\n",
    "                print('Convergence reached at iteration #%d:' % (i + 1))\n",
    "                for m in range (photon_n):\n",
    "                    print('Photon no. %d has x=%f, y=%f, sx=%f, sy=%f, A=%f' %\n",
    "                      (m + 1, para_ls[m][0], para_ls[m][1], para_ls[m][2], para_ls[m][3], para_ls[m][4]))\n",
    "                    print('Distribution matrix of this photon:')\n",
    "                    print(pe_array[m].dist_matrix.astype(int))\n",
    "                print('Current error:%f' % err)\n",
    "                print('-----------Initial iteration ends-------------')\n",
    "            break\n",
    "    \n",
    "    x, y, sx, sy, A = np.transpose(para_ls)\n",
    "    \n",
    "    # ------------Stage 2: attempt to add more photon within the box to further reduce error-------------\n",
    "    \n",
    "    for num in range(photon_n, max_photon):\n",
    "        \n",
    "        # Store the current values\n",
    "        err_tmp = error(pe_array, dat) \n",
    "        x_tmp ,y_tmp, sx_tmp, sy_tmp, A_tmp = np.transpose(para_ls)\n",
    "        \n",
    "        # Calculate the residual distribution \n",
    "        dat_res = deepcopy(dat)\n",
    "        for pe in pe_array:\n",
    "            dat_res = dat_res - pe.dist_matrix.astype(int)\n",
    "        \n",
    "        if(output != 'None'):\n",
    "            print('The current residual distribution:')\n",
    "            print(dat_res)\n",
    "        \n",
    "        # From the residual matrix, check if another photon can be added\n",
    "        dat_sorted = sorted(dat_res.flatten())\n",
    "        if((dat_sorted[-1] < thres and dat_sorted[-2] < thres - 10)):\n",
    "            if(num >= 2): # Another photon must be added if only one photon exists at this stage.\n",
    "                if(output != 'None'):\n",
    "                    print('No more photons to be added. Gradient descent ends.')\n",
    "                break\n",
    "                \n",
    "        # Add one photon at the maximum entry of dat_res\n",
    "        x_new, y_new = np.unravel_index(dat_res.argmax(), dat_res.shape)\n",
    "        if(output != 'None'):\n",
    "            print('One more photon added at x=%g, y=%g; there are currently %d photons in total.' %(x_new + 0.5, y_new + 0.5, num + 1))\n",
    "        x = np.append(x, x_new + 0.5)\n",
    "        y = np.append(y, y_new + 0.5)\n",
    "        \n",
    "        # Reset all other parameters\n",
    "        sx = np.zeros(num + 1) + 0.4\n",
    "        sy = np.zeros(num + 1) + 0.4\n",
    "        A = np.random.uniform(size = num + 1) * 3 + 22\n",
    "        para_ls = np.transpose([x, y, sx, sy, A])\n",
    "        \n",
    "        # Reset all photon events\n",
    "        pe_array = []\n",
    "        for i in range(num+1):\n",
    "            pe_array.append(photon_event(y[i], x[i], sx[i], sy[i], w, h, A[i]))\n",
    "        \n",
    "        err_array = []\n",
    "        if(output != 'None'):\n",
    "            print('----------Iteration #%d starts----------' % (num + 1))\n",
    "        for i in range(max_iter):\n",
    "\n",
    "            # Use descent to obtain the new parameters and the current error, and add the latter to err_array\n",
    "            new_param_ls, err = descent(pe_array, step_ls, dat)\n",
    "            err_array.append(err)\n",
    "\n",
    "            # Change the parameters of the photons\n",
    "            for n in range(num + 1):\n",
    "                # Alter each parameter using the descent function\n",
    "                # A loop is not used here for efficiency\n",
    "                pe_array[n].new_value(new_param_ls[n])\n",
    "                para_ls[n] = new_param_ls[n]\n",
    "            # Check if convergence is reached\n",
    "            if(i >= iter_diff and err_array[i - iter_diff] - err <= err * conv_crit):\n",
    "                if(output != 'None'):\n",
    "                    print('Convergence reached at iteration #%d:' % (i + 1))\n",
    "                    for m in range (num + 1):\n",
    "                        print('Photon no. %d has x=%f, y=%f, sx=%f, sy=%f, A=%f' %\n",
    "                          (m + 1, para_ls[m][0], para_ls[m][1], para_ls[m][2], para_ls[m][3], para_ls[m][4]))\n",
    "                        print('Distribution matrix of this photon:')\n",
    "                        print(pe_array[m].dist_matrix.astype(int))\n",
    "                    print('Current error:%f' % err)\n",
    "                    print('-----------Iteration #%d ends-------------' % (num + 1))\n",
    "                break\n",
    "                \n",
    "        # Compare the error: if adding a photon does not reduce the error, select the old arrangements and break\n",
    "        if(err >= err_tmp - 5):\n",
    "            err = err_tmp\n",
    "            x = x_tmp\n",
    "            y = y_tmp\n",
    "            sx = sx_tmp\n",
    "            sy = sy_tmp\n",
    "            A = A_tmp\n",
    "            if(output != 'None'):\n",
    "                print('Adding this photon however did not reduce error. Returning to the older configuration with %d photons. Gradient descent ends.' \n",
    "                      % num)\n",
    "            break\n",
    "            \n",
    "        x, y, sx, sy, A = np.transpose(para_ls)\n",
    "    \n",
    "    return [x, y, A, err]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9940cc08",
   "metadata": {},
   "source": [
    "As an example, apply the algorithm to one of the boxes in the demo data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent_multi(demo_box_list[7], demo_data, output = 'yes please');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c33c078",
   "metadata": {},
   "source": [
    "### Step 4: Running the SPC algorithm\n",
    "\n",
    "We now create a function that completes the task of single photon counting, invoking the SPE and MPE functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592dd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a class to store the results:\n",
    "class photon_event_result:\n",
    "    'The result of photon event processed. This includes the coordinates and intensity of the event, as well as its classification.'\n",
    "\n",
    "    def __init__(self, event_type, x, y, A):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.A = A\n",
    "        self.type = event_type # event_type is 's' for SPEs and 'm' for MPEs\n",
    "        \n",
    "\n",
    "def single_photon_counting(im_array):\n",
    "    \n",
    "    # Input: an array of normalised image to be processed\n",
    "    # Output: an array of photon_event_result objects, containing the photons identified.\n",
    "    \n",
    "    # an index to count the number of images\n",
    "    image_no = 0\n",
    "    \n",
    "    photon_n = 0 # No. of photons found\n",
    "    s_n = 0 # No. of single photons found\n",
    "    m_n = 0 # No. of photons in MPEs found\n",
    "    \n",
    "    # Start timing\n",
    "    start = time.time()\n",
    "    \n",
    "    #Initialize the photon event result object list\n",
    "    per_list = []\n",
    "    \n",
    "    for im in im_array:\n",
    "        image_no = image_no + 1\n",
    "        print('\\r', 'Preparing image #%d' % image_no, end = '', flush = True)\n",
    "        \n",
    "        # Find the list of boxes in this image\n",
    "        box_list = boxing(thresholding(im, thres))\n",
    "        box_count = 0\n",
    "        box_photon_count = 0\n",
    "\n",
    "        for b in box_list:\n",
    "            box_count = box_count + 1\n",
    "            \n",
    "            # Display some information\n",
    "            end = time.time()\n",
    "\n",
    "            print('\\rImage %d / %d, box %d / %d; # of photons in this image: %d; Total time elapsed: %.1f sec.' \n",
    "            % (image_no, len(im_array), box_count, len(box_list), box_photon_count, end - start), end = '', flush = True)\n",
    "\n",
    "            if(b.hw()[0] <= 4 and b.hw()[1] <= 4): # Single photon events\n",
    "                \n",
    "                spe_event = gradient_descent_single(b, im)\n",
    "                x, y, sx, sy, A, flag = spe_event\n",
    "                \n",
    "                if(flag == 0): # SPE confirmed\n",
    "                    # Transform the x and y coordinates to that of the image\n",
    "                    x = x + b.x_min - 0.5\n",
    "                    y = y + b.y_min - 0.5\n",
    "                    \n",
    "                    per = photon_event_result('s', x, y, A)\n",
    "                    per_list.append(per)\n",
    "                    \n",
    "                    photon_n = photon_n + 1\n",
    "                    box_photon_count = box_photon_count + 1\n",
    "                    s_n = s_n + 1\n",
    "                    \n",
    "                    continue\n",
    "            \n",
    "            #MPE confirmed\n",
    "            mpe_event = gradient_descent_multi(b, im)\n",
    "            \n",
    "            for n in range(len(mpe_event[0])): # Iterate all photons found\n",
    "                # Transform the x and y coordinates to that of the image\n",
    "                x = mpe_event[0][n] + b.x_min - 0.5\n",
    "                y = mpe_event[1][n] + b.y_min - 0.5\n",
    "                A = mpe_event[2][n]\n",
    "                \n",
    "                per = photon_event_result('m', x, y, A)\n",
    "                per_list.append(per)\n",
    "                    \n",
    "                photon_n = photon_n + 1\n",
    "                box_photon_count = box_photon_count + 1\n",
    "                m_n = m_n + 1 \n",
    "    \n",
    "        print(\" Image Done.\")\n",
    "\n",
    "    print('Single photon counting finished.')\n",
    "    print('%d SPEs found; %d MPEs found; total number of photons: %d' % (s_n, m_n, photon_n))\n",
    "    print('Time elapsed: %f seconds' % (end - start))\n",
    "    return per_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78d521",
   "metadata": {},
   "source": [
    "Demonstrating our single photon counting algorithm in the demo data, which have finally fulfilled its purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3138c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_results=single_photon_counting([demo_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the boxes\n",
    "fig, ax = plt.subplots(1)\n",
    "for b in demo_box_list:\n",
    "    box_rect = patches.Rectangle((b.y_min - 0.5, b.x_min - 0.5), b.hw()[0], b.hw()[1],\n",
    "                                                 linewidth = 1, edgecolor = 'r', facecolor = \"none\")\n",
    "    ax.add_patch(box_rect)\n",
    "\n",
    "# Extract the data\n",
    "demo_x, demo_y, demo_A = np.transpose([[per.x, per.y, per.A] for per in demo_results])\n",
    "\n",
    "plt.scatter(demo_y, demo_x, color = 'red', marker = 'o', s = 12 * (np.array(demo_A) - 10))\n",
    "plt.imshow(demo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f107b",
   "metadata": {},
   "source": [
    "Now, run the single photon counting algorithm on our image data:\n",
    "\n",
    "<b>Note: processing of each image would take tens of seconds to a few minutes, depending on the photon density in it. Processing an array of 20 images may take 1-2 hours. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c0d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_result = single_photon_counting(image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ecc9e",
   "metadata": {},
   "source": [
    "Write a function to save the data in a csv file, with each line having three entries of `x, y, A`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86573d1b",
   "metadata": {},
   "source": [
    "<b><u>Enter the path of the csv file to save the data here:</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b45982",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'spc_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01771b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_in_csv(spc_result, name):\n",
    "    with open(name, 'w', newline = '') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for per in spc_result:\n",
    "            x = per.x\n",
    "            y = per.y\n",
    "            A = per.A\n",
    "            t = per.type\n",
    "            writer.writerow([x, y, A, t])\n",
    "\n",
    "def read_from_csv(file_loc):\n",
    "    with open(file_loc, mode = 'r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        A_list = []   \n",
    "        spc_result = []\n",
    "        for lines in csvFile:\n",
    "            x, y, A, t = lines\n",
    "            spc_result.append(photon_event_result(t, float(x), float(y), float(A)))\n",
    "    return spc_result\n",
    "\n",
    "#write_in_csv(spc_result, name = csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2352b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line to read data from the csv file:\n",
    "spc_result = read_from_csv(file_loc = csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e737c",
   "metadata": {},
   "source": [
    "### Step 5: Noise elimination\n",
    "\n",
    "Up until this point, we have not considered the influence of the noise, which may fluctuate above the threshold and create low-intensity spurious events. We will now attempt to eliminate them.\n",
    "\n",
    "The elimination of noise is based on the assumption that the distribution of `A`, the photon intensity, should be Gaussian. We plot the histogram of `A` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [per.x for per in spc_result]\n",
    "y_list = [per.y for per in spc_result]\n",
    "A_list = [per.A for per in spc_result]\n",
    "plt.hist(A_list, bins = 500);\n",
    "plt.rcParams[\"figure.figsize\"]=[12, 12];\n",
    "plt.xlim([0, 80]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd88c4",
   "metadata": {},
   "source": [
    "It can be seen that `A` indeed follows a Gaussian distribution, but the region below `A = 10` and above `A = 40` are spurious. The latter is due to that we sometimes count two photons at the same pixel or adjacent pixels as one; the former, on the other hand, is due to noise.\n",
    "\n",
    "In our noise elimination process, we eliminated the spurious low-intensity events until a Gaussian distribution is restored on the left side. This is created by first fitting a Gaussian distribution using the middle section of the histogram, and eliminate events in each of the low-intensity bins until the remaining number of events conforms to the distribution fitted. For each event with `A < gauss_min`, with `gauss_min` the lower bound of the region with which we will perform the fit, the chance of keeping it is the ratio of the value of the Gaussian fit at `A` and the number of events in the bin in which it lives.\n",
    "\n",
    "Also, in this process we generate the statistics of the number and the uncertainty of photons.\n",
    "\n",
    "For the statistics of photon numbers, each valid photon with intensity `A` is counted as $A/\\mu_A$ photons, where $\\mu_A$ is the mean of the Gaussian fitted,\n",
    "\n",
    "We also need to find the uncertainty of the photon number founded in this way. Two factors contribute to the uncertainty:\n",
    "\n",
    "- Due to the probabilitistic approach of our filtering algorithm: each time we have a low-intensity event with probability $p$, no matter we select it or not, an uncertainty of $\\sqrt{p(1-p)}$ is generated.\n",
    "\n",
    "- The algorithm may consider two adjacent photon events to be one with large intensity by mistake. Whenever we see an event with intensity `A > gauss_max`, an uncertainty of $\\sqrt{x(1-x)}$ is generated, where $x=A/\\mu_A-1$, with a maximum of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the boundaries of the region with which we are going to fit the Gaussian.\n",
    "gauss_min = 12\n",
    "gauss_max = 30\n",
    "\n",
    "# Specify the number of bins that is going to be used in the following function to bin the events\n",
    "_bins = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d876090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_filtering(spc_result):\n",
    "    \n",
    "    # Input: the list of the result; the number of bins into which we divide our result\n",
    "    # Output: filtered results, as well as their x, y and A for further manipulations\n",
    "    \n",
    "    # Generate the list containing the intensity values\n",
    "    A_list = [per.A for per in spc_result]\n",
    "\n",
    "    # Define the edge of the bins; we only use the part of the histogram with A < gauss_max. \n",
    "    x_bins = np.linspace(0, gauss_max, _bins)\n",
    "    \n",
    "    # Find the value in each bin\n",
    "    A_bins = np.zeros(_bins)\n",
    "    for a in A_list:\n",
    "        if(a < gauss_max):\n",
    "            A_bins[int(a / gauss_max * _bins)] = A_bins[int(a / gauss_max * _bins)] + 1\n",
    "        \n",
    "    # Obtain the part of the histogram that we are going to use to perform the fit:\n",
    "    start_bins = int(gauss_min / gauss_max * _bins)\n",
    "    fit_A = A_bins[start_bins: ]\n",
    "    fit_x = x_bins[start_bins: ]\n",
    "    \n",
    "    # Perform the fit\n",
    "    def gaussian(x, A0, x0, sigma):\n",
    "        return A0 * np.exp(-(x - x0)**2 / (2 * sigma**2))\n",
    "    \n",
    "    popt, pcov = curve_fit(\n",
    "        f = gaussian, # model function\n",
    "        xdata = fit_x, # x data\n",
    "        ydata = fit_A, # y data\n",
    "        p0 = (30000, 20, 10) # initial guess of parameters\n",
    "    )\n",
    "    \n",
    "    #Plot the histogram of intensities before filtering, along with the fitted curve\n",
    "    x_ls = np.linspace(0, 80, 800)\n",
    "    plt.rcParams[\"figure.figsize\"]=[20, 10];\n",
    "    fig, (before, after) = plt.subplots(ncols=2)\n",
    "    before.set_xlim([0, 80])\n",
    "    before.hist(A_list, bins = int(_bins / gauss_max * 80), range = [0,80]);\n",
    "    before.plot(x_ls, gaussian(x_ls,popt[0],popt[1],popt[2]));\n",
    "    before.set_title('Before filtering')\n",
    "    \n",
    "    # Start event filtering and photon counting:\n",
    "    \n",
    "    photon_n = 0 # Photon number\n",
    "    photon_sigma = 0 # Photon uncertainty\n",
    "    \n",
    "    filtered_spc = []\n",
    "    for per in spc_result:\n",
    "        if(per.A <= 0): # Filter invalid events\n",
    "            continue\n",
    "        elif(per.A < gauss_min): \n",
    "            # For low intensity events, the probability of keeping this event \n",
    "            # p = value of the Gaussian fit at its intensity / # of events in the bin it belongs to, with a maximum of 1\n",
    "            p = min(1, \n",
    "                    (gaussian(per.A, popt[0], popt[1], popt[2]) / \n",
    "                     max(A_bins[int(per.A / gauss_max * _bins)], 1))) # prevent the possibility of divide by zero\n",
    "            \n",
    "            if(np.random.rand() <= p):\n",
    "                filtered_spc.append(per)\n",
    "                photon_n = photon_n + per.A / popt[1]\n",
    "            photon_sigma = photon_sigma + np.sqrt(p * (1 - p))\n",
    "        else:\n",
    "            filtered_spc.append(per)\n",
    "            photon_n = photon_n + per.A / popt[1]\n",
    "            if(per.A > gauss_max):\n",
    "                x = min(1, per.A / popt[1] - 1)\n",
    "                photon_sigma = photon_sigma + np.sqrt(x * (1 - x))\n",
    "    \n",
    "    x_list = [per.x for per in filtered_spc]\n",
    "    y_list = [per.y for per in filtered_spc]\n",
    "    A_list = [per.A for per in filtered_spc]\n",
    "    \n",
    "    # Plot the histogram of intensities after filtering, along with the fitted curve\n",
    "    after.set_xlim([0, 80])\n",
    "    after.hist(A_list, bins = int(_bins / gauss_max * 80), range = [0,80]);\n",
    "    after.plot(x_ls, gaussian(x_ls,popt[0],popt[1],popt[2]));\n",
    "    after.set_title('After filtering')\n",
    "    \n",
    "    return [[photon_n, photon_sigma], x_list, y_list, A_list, filtered_spc]\n",
    "            \n",
    "[photon_n, photon_sigma], x_list, y_list, A_list, filtered_spc = event_filtering(spc_result);\n",
    "print('Total photon number: %d ± %d' % (photon_n, photon_sigma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068505f",
   "metadata": {},
   "source": [
    "We have thus completed the single photon counting part of the algorithm, and will now use the data processed, namely the x- and y-coordinate list and intensity list to fit the spectral lines and plot the final energy spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8026b39d",
   "metadata": {},
   "source": [
    "## Bragg Spectroscopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9afe916",
   "metadata": {},
   "source": [
    "We first plot all the photons found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]=[12, 12];\n",
    "plt.scatter(y_list, x_list, s = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4a022",
   "metadata": {},
   "source": [
    "One can see clear spectral lines on the plot. In the following steps, we will extract points that lies on the lines, use them and the knowledge of the energies of the spectral lines to fit the geometry; using that, we can find the energy associated to each photon, and plot out the final spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e13b9",
   "metadata": {},
   "source": [
    "### Step 1: Finding points on the spectral lines\n",
    "\n",
    "We begin by again cutting our image generated in the previous step into `fit_cut_num` strips; within each strip, we would like to fine `n` y-coordiantes having the greatest photon densities, where `n` is the number of spectral lines present. This is realised by performing the following steps:\n",
    "- Within each cut, run a moving average function to calculate, for each `y`, the number of photons within the range `y` $\\pm$ `half_width`. Store the result in an array, `moving_average`.\n",
    "- Find the peaks by identifying the set\n",
    "$$\n",
    "    \\left\\{\\mathtt{i  |  moving\\_average[i] = max(moving\\_average[i - peak\\_width : i+peak\\_width])}\\right\\}\n",
    "$$\n",
    "i.e. identifying all peaks in the moving average array; then, pick the greatest `n` entries.\n",
    "- Return the set of points found in each cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters mentioned above\n",
    "fit_cut_num = 32\n",
    "half_width = 10\n",
    "peak_width = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e1e67",
   "metadata": {},
   "source": [
    "<b><u>Enter the energies, in units of eV, of spectral lines here, from low to high:</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ec24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_energies = 1188, 1218.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0383e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the number of spectral lines\n",
    "spec_n = len(spec_energies)\n",
    "\n",
    "def moving_avg(strip_dat):\n",
    "    \n",
    "    # Input: data in a single strip, containing the x- and y- coordinates of photons.\n",
    "    # Output: moving_average, a length (2048 - half_width) array described above.\n",
    "    \n",
    "    # Initialise the moving_average array:\n",
    "    moving_average = np.zeros(2048 - half_width)\n",
    "    \n",
    "    # Iterate each photon event, and add a count to all entries in moving_average with distance < half_width\n",
    "    for e in strip_dat:\n",
    "        y = e[1]\n",
    "        \n",
    "        start = max(0, int(y) - half_width + 1)\n",
    "        end = min(2048 - half_width, int(y) + half_width)\n",
    "        \n",
    "        moving_average[start:end] = moving_average[start:end] + 1\n",
    "    \n",
    "    return moving_average\n",
    "\n",
    "def point_finding(x_list, y_list):\n",
    "    \n",
    "    # Input: the x- and y- coordinates of photons\n",
    "    # Output: within each strip, the coordinate of n points lying on each of the spectral lines\n",
    "    \n",
    "    # Sort the data based on x-coordinates in order to cut it\n",
    "    data = np.transpose([x_list, y_list])\n",
    "    x_list, y_list = np.transpose(data[data[:, 0].argsort()])\n",
    "    \n",
    "    # Make sure that fit_cut_num is a factor of the size of the image, i.e. 2048. If not, raise an error.\n",
    "    try:\n",
    "        cut_height = int(2048/fit_cut_num)\n",
    "        if(cut_height * fit_cut_num != 2048):\n",
    "            raise ValueError('Invalid norm_cut_num')\n",
    "    except ValueError as e:\n",
    "        print('Error: ', e)\n",
    "    \n",
    "    point_ls = [[] for i in range(spec_n)]\n",
    "\n",
    "    # store the cutting points in the array of coordinates\n",
    "    cut_points = [0]\n",
    "    \n",
    "    for n in range(fit_cut_num):\n",
    "        # Find the next cutting point\n",
    "        for i in range(cut_points[-1], len(x_list)):\n",
    "            if(x_list[i] > (n+1) * cut_height):\n",
    "                # Store the cut point\n",
    "                cut_points.append(i)\n",
    "                break\n",
    "                \n",
    "        # Obtain the strip data:\n",
    "        begin = cut_points[-2]\n",
    "        end = cut_points[-1]\n",
    "        dat = np.transpose([x_list[begin:end], y_list[begin:end]])\n",
    "        moving_average = moving_avg(dat)\n",
    "\n",
    "        # Find the peaks using methods described above:\n",
    "        peaks = np.zeros([spec_n, 2]) # A n*2 array, used to store the values and positions of peaks\n",
    "                \n",
    "        for i in range(len(moving_average)):\n",
    "            begin = max(0, i - peak_width)\n",
    "            end = min(2048, i + peak_width)\n",
    "            if(moving_average[i] == max(moving_average[begin:end])): # peak found\n",
    "                if(i >= 5 and moving_average[i] == max(moving_average[i-5:i])): # avoid counting the same peak twice\n",
    "                    continue\n",
    "                if(spec_n == 1): # Only one spectral line:\n",
    "                    if(moving_average[i] > peaks[0][1]):\n",
    "                        peaks[0][1] = moving_average[i]\n",
    "                        peaks[0][0] = i\n",
    "                elif(peaks[-1][1] < moving_average[i]): # The current peak is larger than at least one of the peaks stored\n",
    "                    # Remove the last entry of peaks, which, upon sorting later, is the smallest\n",
    "                    peaks[-1] = (i, moving_average[i])\n",
    "                    peaks = sorted(peaks, key = lambda x: x[1], reverse = True)\n",
    "        \n",
    "        # Sort the peaks with their coordinates, to make sure that they corresponds to the correct spectral line\n",
    "        peaks = sorted(peaks, key = lambda x: x[0], reverse = True)\n",
    "        # Add the peaks found to the point list; their x-coordinate is taken to be that of the middle of the strip\n",
    "        for m in range(spec_n):\n",
    "            point_ls[m].append([int(n * cut_height + cut_height / 2),\n",
    "                                     np.transpose(peaks)[0][m] + half_width / 2]) \n",
    "            # The additional term in the second entry is to compensate for the moving average\n",
    "            \n",
    "    return point_ls\n",
    "point_ls = point_finding(x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e87339",
   "metadata": {},
   "source": [
    "Apply this algorithm in our data and plot the points on the scatter plot of photon events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8dc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_list, x_list, s = 0.1)\n",
    "for points in point_ls:\n",
    "    point_x = np.transpose(points)[0]\n",
    "    point_y = np.transpose(points)[1]\n",
    "    plt.scatter(point_y, point_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5df2b",
   "metadata": {},
   "source": [
    "### Step 2: Fitting the geometry\n",
    "\n",
    "For details of this step, see the report. Here, we only claim that for each point with coordinates $x,y$, \n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    &\\left\\{-l\\sin\\alpha + \\left[(x-x_0)\\sin\\varphi + (y-y_0)\\cos\\varphi\\right]\\cos\\alpha \\right\\} ^2 \n",
    "    + \\left[(x-x_0)\\cos\\varphi - (y-y_0) \\sin\\varphi \\right]^2\n",
    "    \\\\\n",
    "    &=\\left\\{l\\cos\\alpha + \\left[(x-x_0)\\sin\\varphi + (y-y_0)\\cos\\varphi\\right]\\sin\\alpha \\right\\} ^2 \\cot^2\\theta\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "where $l$ is the distance between the deflecting beryl crystal and the camera, in units of pixels; $\\alpha$ is the angle between the beryl crystal and the CCD, in radians, $\\varphi$ is the angle by which the camera is rotated, and $x_0, y_0$ are the coordinate of the projection of the deflection point on the camera. They are all parameters to be determined. $\\theta$ is related to the photon energy by Bragg's law:\n",
    "$$\n",
    "    n \\frac{hc}{E}=2d \\sin\\theta\n",
    "$$\n",
    "\n",
    "We now use the knowledge of the spectral lines to find the five parameters $l, \\alpha, \\varphi, x_0, y_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85187837",
   "metadata": {},
   "source": [
    "<b><u>Enter the values of $n$ and $2d$ in units of angstrom here:</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_n = 1\n",
    "fit_2d = 15.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d770d",
   "metadata": {},
   "source": [
    "<b><u>If a new set of initial values for the parameters $l, \\alpha, \\varphi, x_0, y_0$ are to be used, enter them here:</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_init = 6000\n",
    "alpha_init = 1\n",
    "phi_init = 0\n",
    "x0_init = 800\n",
    "y0_init = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcda72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Bragg's law, calculate the value of theta corresponding to each spectral line\n",
    "theta_ls = [np.arcsin(fit_n * 12398.4 / (energy * fit_2d)) for energy in spec_energies]\n",
    "\n",
    "def geometry(point_ls):\n",
    "    \n",
    "    # Input: the list of points obtained in previous steps\n",
    "    # Output: estimation of the five parameters\n",
    "    \n",
    "    # Define a function to calculate the error of a single point, defined to be the square of the difference\n",
    "    # of the LHS and the RHS of the above expression\n",
    "    def point_error(x, y, l, alpha, phi, x0, y0, theta):\n",
    "        x = x - x0\n",
    "        y = y - y0\n",
    "\n",
    "        calc_theta = np.arctan(np.sqrt(((-l * np.sin(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.cos(alpha))**2\n",
    "               + (x * np.cos(phi) - y * np.sin(phi))**2 ) /\n",
    "               ((l * np.cos(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.sin(alpha))**2))**-1)\n",
    "        calc_energy = fit_n * 12398.4 / fit_2d / np.sin(calc_theta)\n",
    "        real_energy = fit_n * 12398.4 / fit_2d / np.sin(theta)\n",
    "        #print(calc_energy, real_energy)\n",
    "        return (calc_energy - real_energy)**2\n",
    "    \n",
    "    # Define a function that calculates the total error, with the only parameter being a list of parameters for fitting,\n",
    "    # to be used in scipy.optimize.least_squares later\n",
    "    def total_error(params):\n",
    "        l, alpha, phi, x0, y0 = params\n",
    "\n",
    "        err = 0\n",
    "        for i in range(len(point_ls)):\n",
    "            points = point_ls[i]\n",
    "            theta = theta_ls[i]\n",
    "            for point in points:\n",
    "                x, y = point\n",
    "                err = err + point_error(x, y, l, alpha, phi, x0, y0, theta)\n",
    "        return err\n",
    "    \n",
    "    # Set the initial array of parameters\n",
    "    params = np.array([l_init, alpha_init, phi_init, x0_init, y0_init])\n",
    "    \n",
    "    # Use another gradient descent method to obtain the optima of parameters.\n",
    "    fit_step = [3, 0.0001, 0.00001, 0.3, 0.3]\n",
    "    descent_factor = 0.5\n",
    "    for i in range(400):\n",
    "        tot_err = total_error(params)\n",
    "        err = [total_error(p) for p in params + np.diag(fit_step)] - tot_err\n",
    "        params = params - fit_step * err * descent_factor\n",
    "        if(tot_err < 20):\n",
    "            break\n",
    "\n",
    "    # Run a least squares fit to further optimize the result:\n",
    "    res = least_squares(total_error, params, \n",
    "                        bounds = ([0, 0, -np.pi, 0, 0],[np.inf, 2 * np.pi, np.pi, 2048, 2048]),\n",
    "                       verbose = 0, xtol = 1e-10\n",
    "                 )\n",
    "    print('The parameters fitted are: l = %dpx, alpha = %.3f, phi = %f, x0 = %.1fpx, y0 = %.1fpx' % (params[0],params[1],params[2],params[3],params[4]))\n",
    "    return params\n",
    "\n",
    "params = geometry(point_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64d16a",
   "metadata": {},
   "source": [
    "### Step 3: Finding the energy of each photon, plot the final spectrum\n",
    "\n",
    "With the geometry fitted, the value of $\\theta$ and hence energy of each photon can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(x, y, params):\n",
    "    \n",
    "    # Input: coordinates of the photon, the params fitted\n",
    "    # Output: energy of the photon\n",
    "    \n",
    "    l, alpha, phi, x0, y0 = params\n",
    "    \n",
    "    x = x - x0\n",
    "    y = y - y0\n",
    "    \n",
    "    denumerator = (-l * np.sin(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.cos(alpha))**2 + (x *np.cos(phi) - y * np.sin(phi))**2 \n",
    "    numerator = (l * np.cos(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.sin(alpha))**2\n",
    "\n",
    "    theta = np.arctan(np.sqrt(numerator / denumerator))\n",
    "    \n",
    "    # Use the energy and theta of the first spectral line to deeuce the energy:\n",
    "    \n",
    "    e1 = spec_energies [0]\n",
    "    theta_1 = theta_ls [0]\n",
    "    \n",
    "    return e1 * np.sin(theta_1) / np.sin(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a871418",
   "metadata": {},
   "source": [
    "We may now generate the final spectrum.\n",
    "\n",
    "Note that the contribution of each photon to their energy bin is proportional to `A`. Moreover, the final intensity value of each energy bin must be multiplied by a correction factor. This is to account for the fact that, with all photons having the same energy lying on a cone, only a portion of them fall on the CCD. The angle that this portion corresponds to, $\\psi$, is different for each energies. For details of this correction factor, see the report.\n",
    "\n",
    "<b><u>Enter the values of the minimum and maximum energy here, in units of eV:</u></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeae561",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_e = 1100\n",
    "max_e = 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1be157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(x_list, y_list, A_list, bins, _params = params):\n",
    "    \n",
    "    # Input: lists of coordinates and intensities of photons, the desired # of bins of the plot, and the parameters of the geometry \n",
    "    #        obtained before.\n",
    "    # Output; the plot\n",
    "    \n",
    "    l, alpha, phi, x0, y0 = _params\n",
    "    \n",
    "    # Store the energies\n",
    "    energies = []\n",
    "    \n",
    "    # Initialise the value of each energy bins\n",
    "    energy_plot=np.zeros(bins)\n",
    "    \n",
    "    denom=1 / (max_e - min_e)\n",
    "    \n",
    "    # Generate correction\n",
    "    def f(y, x, theta):\n",
    "        x = x - x0\n",
    "        y = y - y0\n",
    "        return ((-l * np.sin(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.cos(alpha))**2\n",
    "                   + (x * np.cos(phi) - y * np.sin(phi))**2 \n",
    "                   - (l * np.cos(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.sin(alpha))**2 * np.tan(theta)**-2\n",
    "                   )\n",
    "    \n",
    "    correction = []\n",
    "    for i in range(bins):\n",
    "        e = min_e + (max_e - min_e) / bins * i\n",
    "        theta = np.arcsin(spec_energies[0] * np.sin(theta_ls[0]) / e)\n",
    "        y_top = fsolve(f, 1500, args = (2048,theta))[0]\n",
    "        y_bot = fsolve(f, 1500, args = (0, theta))[0]\n",
    "        \n",
    "        psi = []\n",
    "        for x,y in [[2048, y_top],[0, y_bot]]:\n",
    "            x = x - x0\n",
    "            y = y - y0\n",
    "            x_pp = (-l * np.sin(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.cos(alpha))\n",
    "            y_pp = (x * np.cos(phi) - y * np.sin(phi))\n",
    "            psi.append(np.arctan(x_pp / y_pp))\n",
    "        correction.append((2 * np.pi + psi[0] - psi[1]) / (2 * np.pi))\n",
    "\n",
    "    # Get the value of each energy bin, by iterating all photons and add their contribution to the corresponding bins\n",
    "    for i in range(len(x_list)):\n",
    "        e = energy(x_list[i],y_list[i], params)\n",
    "        if(e > min_e and e < max_e):\n",
    "            index = int((e - min_e) * denom * bins)\n",
    "            energy_plot[index]=energy_plot[index] + A_list[i] / correction[index]\n",
    "    \n",
    "    # Plot the final spectrum\n",
    "    plt.xlim([1100,1600])\n",
    "    \n",
    "    plt.semilogy()\n",
    "    plt.plot(np.linspace(min_e,max_e,len(energy_plot)),energy_plot);\n",
    "    \n",
    "    plt.ylabel('Intensity(a.u.)',fontsize = 20);\n",
    "    plt.xlabel('Energy(eV)',fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f950e46d",
   "metadata": {},
   "source": [
    "<b><u>Enter the number of bins in the final plot here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a177ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot(x_list, y_list, A_list, bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee3510",
   "metadata": {},
   "source": [
    "## Control group\n",
    "\n",
    "As a comparison, the following function plots the spectrum obtained by using Bragg's spectroscopy only. The function iterates all grids and yield a value proportional to the average ADU value of the pixels within for each energy bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354ef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "denom=1 / (max_e - min_e)\n",
    "h, w = image_data[0].shape\n",
    "energy_bin = np.zeros([h, w])\n",
    "for i in range(h):\n",
    "    print('\\r%d' % i, end = '', flush = True)\n",
    "    for j in range(w):\n",
    "        e = energy(i + 0.5, j + 0.5, params)\n",
    "        if(e > min_e and e < max_e):\n",
    "            energy_bin[i, j] = int((e - min_e) * denom * bins)\n",
    "        else:\n",
    "            energy_bin[i, j] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = plt.hist(energy_bin.flatten(), bins = 400, range = [0, 399])[0]\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5be64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(energy_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf649d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_2(im_arr, bins, _params = params):\n",
    "    \n",
    "    # Input: an array of original images after normalisation, the desired # of bins of the plot, and the parameters of the geometry \n",
    "    #        obtained before.\n",
    "    # Output; the plot\n",
    "    \n",
    "    l, alpha, phi, x0, y0 = _params\n",
    "    \n",
    "    # Store the energies\n",
    "    energies = []\n",
    "    \n",
    "    # Initialise the value of each energy bins\n",
    "    energy_plot = np.zeros(bins)\n",
    "    \n",
    "    # Initialise the array containing # of pixels within each energy bin, for normalisation purposes.\n",
    "    freq = np.zeros(bins)\n",
    "    \n",
    "    denom=1 / (max_e - min_e)\n",
    "    \n",
    "    # Find the energy bin that each of the pixels belongs to\n",
    "    h, w = image_data[0].shape\n",
    "    energy_bin = np.zeros([h, w])\n",
    "    for i in range(h):\n",
    "        print('\\rGenerating energy bin data: Line %d / %d' % (i + 1, h), end = '', flush = True)\n",
    "        for j in range(w):\n",
    "            e = energy(i + 0.5, j + 0.5, params)\n",
    "            if(e > min_e and e < max_e):\n",
    "                energy_bin[i, j] = int((e - min_e) * denom * bins)\n",
    "                freq[int((e - min_e) * denom * bins)] = freq[int((e - min_e) * denom * bins)] + 1\n",
    "            else:\n",
    "                energy_bin[i, j] = -1\n",
    "    \n",
    "    \n",
    "    # Generate correction\n",
    "    def f(y, x, theta):\n",
    "        x = x - x0\n",
    "        y = y - y0\n",
    "        return ((-l * np.sin(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.cos(alpha))**2\n",
    "                   + (x * np.cos(phi) - y * np.sin(phi))**2 \n",
    "                   - (l * np.cos(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.sin(alpha))**2 * np.tan(theta)**-2\n",
    "                   )\n",
    "    \n",
    "    correction = []\n",
    "    for i in range(bins):\n",
    "        e = min_e + (max_e - min_e) / bins * i\n",
    "        theta = np.arcsin(spec_energies[0] * np.sin(theta_ls[0]) / e)\n",
    "        y_top = fsolve(f, 1500, args = (2048,theta))[0]\n",
    "        y_bot = fsolve(f, 1500, args = (0, theta))[0]\n",
    "        \n",
    "        psi = []\n",
    "        for x,y in [[2048, y_top],[0, y_bot]]:\n",
    "            x = x - x0\n",
    "            y = y - y0\n",
    "            x_pp = (-l * np.sin(alpha) + (x * np.sin(phi) + y * np.cos(phi)) * np.cos(alpha))\n",
    "            y_pp = (x * np.cos(phi) - y * np.sin(phi))\n",
    "            psi.append(np.arctan(x_pp / y_pp))\n",
    "        correction.append((2 * np.pi + psi[0] - psi[1]) / (2 * np.pi))\n",
    "\n",
    "    # Get the value of each energy bin, by iterating all pxs in every image and add their contribution to the corresponding bins\n",
    "    image_count = 1\n",
    "    print('') # newline\n",
    "    for im in im_arr:\n",
    "        print('\\r', 'Processing image %d' % image_count, end = '', flush = True)\n",
    "        image_count = image_count + 1\n",
    "        for i in range(im.shape[0]):\n",
    "            for j in range(im.shape[1]):\n",
    "                if(energy_bin[i, j] != -1):\n",
    "                    index = int(energy_bin[i, j])\n",
    "                    #print(index)\n",
    "                    energy_plot[index]=energy_plot[index] + im[i,j]  / freq[index] / correction[index]\n",
    "    \n",
    "    # Plot the final spectrum\n",
    "    plt.xlim([1100,1600])\n",
    "    \n",
    "    plt.semilogy()\n",
    "    plt.plot(np.linspace(min_e,max_e,len(energy_plot)),energy_plot);\n",
    "    \n",
    "    plt.ylabel('Intensity(a.u.)',fontsize = 20);\n",
    "    plt.xlabel('Energy(eV)',fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07237a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot_2(image_data, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16750a5d",
   "metadata": {},
   "source": [
    "Not only does this method provides a false prediction of the spectrum after 1500eV, the signal-to-noise ratio is poor, with the value of ratio between maximum intensity and minimum intensity being only $\\sim5$(whereas for the above method combining SPC and Bragg spectroscopy this value is about $50$), rendering Bragg spectroscopy alone not suitable when high precision is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa5bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
